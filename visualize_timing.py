#!/usr/bin/env python3
"""
4DGSè®­ç»ƒæ—¶é—´å¯è§†åŒ–åˆ†æå·¥å…·
åˆ†ææ¯è½®ç”¨æ—¶æ›²çº¿å’Œå„éƒ¨åˆ†çš„å æ¯”
"""

import json
import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path
import argparse
import sys

# å°è¯•å¯¼å…¥seabornï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨matplotlib
try:
    import seaborn as sns
    HAS_SEABORN = True
except ImportError:
    HAS_SEABORN = False
    print("âš ï¸  seabornæœªå®‰è£…ï¼Œå°†ä½¿ç”¨matplotlibç»˜åˆ¶çƒ­åŠ›å›¾")

# è®¾ç½®å­—ä½“ï¼ˆä½¿ç”¨è‹±æ–‡é¿å…å­—ä½“é—®é¢˜ï¼‰
plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class TimingVisualizer:
    def __init__(self, timing_report_path):
        """åˆå§‹åŒ–å¯è§†åŒ–å™¨"""
        self.timing_report_path = Path(timing_report_path)
        self.data = None
        self.load_data()
        
    def load_data(self):
        """åŠ è½½æ—¶é—´æŠ¥å‘Šæ•°æ®"""
        try:
            with open(self.timing_report_path, 'r', encoding='utf-8') as f:
                self.data = json.load(f)
            print(f"âœ… æˆåŠŸåŠ è½½æ—¶é—´æŠ¥å‘Š: {self.timing_report_path}")
        except Exception as e:
            print(f"âŒ åŠ è½½æ—¶é—´æŠ¥å‘Šå¤±è´¥: {e}")
            sys.exit(1)
    
    def extract_iteration_data(self):
        """æå–æ¯è½®è¿­ä»£æ•°æ®"""
        per_iteration = self.data.get('per_iteration_timings', {})
        training_logs = self.data.get('training_logs', [])
        
        iterations = []
        total_times = []
        stages = []
        losses = []
        psnrs = []
        
        # æå–æ¯è½®æ€»ç”¨æ—¶
        for iter_num, timings in per_iteration.items():
            if isinstance(timings, dict):
                for key, time_val in timings.items():
                    if key.endswith('_total'):
                        iterations.append(int(iter_num))
                        total_times.append(time_val)
                        stage = key.replace('_total', '')
                        stages.append(stage)
                        break
        
        # æå–è®­ç»ƒæŒ‡æ ‡
        log_dict = {log['iteration']: log for log in training_logs}
        for iter_num in iterations:
            if iter_num in log_dict:
                losses.append(log_dict[iter_num].get('loss', 0))
                psnrs.append(log_dict[iter_num].get('psnr', 0))
            else:
                losses.append(0)
                psnrs.append(0)
        
        return {
            'iterations': iterations,
            'total_times': total_times,
            'stages': stages,
            'losses': losses,
            'psnrs': psnrs
        }
    
    def extract_operation_data(self):
        """æå–å„æ“ä½œæ•°æ®"""
        per_iteration = self.data.get('per_iteration_timings', {})
        
        # æ”¶é›†æ‰€æœ‰æ“ä½œåç§°
        all_operations = set()
        for timings in per_iteration.values():
            if isinstance(timings, dict):
                for key in timings.keys():
                    if not key.endswith('_total'):
                        all_operations.add(key)
        
        # æŒ‰é˜¶æ®µåˆ†ç»„æ“ä½œ
        coarse_ops = [op for op in all_operations if op.startswith('coarse_')]
        fine_ops = [op for op in all_operations if op.startswith('fine_')]
        
        # æå–æ•°æ®
        operation_data = {}
        for op in all_operations:
            operation_data[op] = []
        
        iterations = []
        for iter_num, timings in per_iteration.items():
            if isinstance(timings, dict):
                iterations.append(int(iter_num))
                for op in all_operations:
                    operation_data[op].append(timings.get(op, 0))
        
        return {
            'iterations': sorted(iterations),
            'operations': operation_data,
            'coarse_ops': coarse_ops,
            'fine_ops': fine_ops
        }
    
    def plot_iteration_timing_curve(self, save_path=None):
        """ç»˜åˆ¶æ¯è½®ç”¨æ—¶æ›²çº¿"""
        data = self.extract_iteration_data()
        
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))
        
        # æŒ‰é˜¶æ®µåˆ†ç»„æ•°æ®
        coarse_data = {'iterations': [], 'times': [], 'losses': [], 'psnrs': []}
        fine_data = {'iterations': [], 'times': [], 'losses': [], 'psnrs': []}
        
        for i, stage in enumerate(data['stages']):
            if stage == 'coarse':
                coarse_data['iterations'].append(data['iterations'][i])
                coarse_data['times'].append(data['total_times'][i])
                coarse_data['losses'].append(data['losses'][i])
                coarse_data['psnrs'].append(data['psnrs'][i])
            elif stage == 'fine':
                fine_data['iterations'].append(data['iterations'][i])
                fine_data['times'].append(data['total_times'][i])
                fine_data['losses'].append(data['losses'][i])
                fine_data['psnrs'].append(data['psnrs'][i])
        
        # ç»˜åˆ¶ç”¨æ—¶æ›²çº¿
        if coarse_data['iterations']:
            ax1.plot(coarse_data['iterations'], coarse_data['times'], 
                    'o-', label='Coarseé˜¶æ®µ', color='blue', alpha=0.7)
        if fine_data['iterations']:
            ax1.plot(fine_data['iterations'], fine_data['times'], 
                    'o-', label='Fineé˜¶æ®µ', color='red', alpha=0.7)
        
        ax1.set_xlabel('Iteration')
        ax1.set_ylabel('Time per Iteration (seconds)')
        ax1.set_title('Training Time per Iteration')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # ç»˜åˆ¶æŸå¤±å’ŒPSNRæ›²çº¿
        if coarse_data['iterations']:
            ax2_twin = ax2.twinx()
            ax2.plot(coarse_data['iterations'], coarse_data['losses'], 
                    'o-', label='CoarseæŸå¤±', color='blue', alpha=0.7)
            ax2_twin.plot(coarse_data['iterations'], coarse_data['psnrs'], 
                         's-', label='Coarse PSNR', color='lightblue', alpha=0.7)
        
        if fine_data['iterations']:
            ax2.plot(fine_data['iterations'], fine_data['losses'], 
                    'o-', label='FineæŸå¤±', color='red', alpha=0.7)
            ax2_twin.plot(fine_data['iterations'], fine_data['psnrs'], 
                         's-', label='Fine PSNR', color='pink', alpha=0.7)
        
        ax2.set_xlabel('Iteration')
        ax2.set_ylabel('Loss', color='black')
        ax2_twin.set_ylabel('PSNR', color='gray')
        ax2.set_title('Training Metrics')
        ax2.legend(loc='upper left')
        ax2_twin.legend(loc='upper right')
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š ç”¨æ—¶æ›²çº¿å›¾å·²ä¿å­˜: {save_path}")
        
        plt.show()
    
    def plot_operation_breakdown(self, save_path=None):
        """ç»˜åˆ¶æ“ä½œå æ¯”åˆ†æ"""
        data = self.extract_operation_data()
        
        # è®¡ç®—å¹³å‡å æ¯”
        avg_percentages = {}
        for op, times in data['operations'].items():
            if times and any(t > 0 for t in times):
                avg_time = np.mean([t for t in times if t > 0])
                avg_percentages[op] = avg_time
        
        # æŒ‰é˜¶æ®µåˆ†ç»„
        coarse_avg = {op: avg_percentages[op] for op in data['coarse_ops'] if op in avg_percentages}
        fine_avg = {op: avg_percentages[op] for op in data['fine_ops'] if op in avg_percentages}
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # Coarseé˜¶æ®µå æ¯”
        if coarse_avg:
            ops = [op.replace('coarse_', '') for op in coarse_avg.keys()]
            times = list(coarse_avg.values())
            colors = plt.cm.Set3(np.linspace(0, 1, len(ops)))
            
            wedges, texts, autotexts = ax1.pie(times, labels=ops, autopct='%1.1f%%', 
                                             colors=colors, startangle=90)
            ax1.set_title('Coarse Stage Operation Time Distribution')
        
        # Fineé˜¶æ®µå æ¯”
        if fine_avg:
            ops = [op.replace('fine_', '') for op in fine_avg.keys()]
            times = list(fine_avg.values())
            colors = plt.cm.Set3(np.linspace(0, 1, len(ops)))
            
            wedges, texts, autotexts = ax2.pie(times, labels=ops, autopct='%1.1f%%', 
                                             colors=colors, startangle=90)
            ax2.set_title('Fine Stage Operation Time Distribution')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š æ“ä½œå æ¯”å›¾å·²ä¿å­˜: {save_path}")
        
        plt.show()
    
    def plot_operation_trends(self, save_path=None):
        """ç»˜åˆ¶å„æ“ä½œç”¨æ—¶è¶‹åŠ¿"""
        data = self.extract_operation_data()
        
        # é€‰æ‹©ä¸»è¦æ“ä½œè¿›è¡Œå¯è§†åŒ–
        main_operations = ['data_loading', 'render', 'loss_computation', 'optimizer_step']
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        axes = axes.flatten()
        
        for i, op in enumerate(main_operations):
            if i >= len(axes):
                break
                
            ax = axes[i]
            
            # ç»˜åˆ¶coarseå’Œfineé˜¶æ®µçš„æ•°æ®
            coarse_op = f'coarse_{op}'
            fine_op = f'fine_{op}'
            
            if coarse_op in data['operations']:
                coarse_times = data['operations'][coarse_op]
                coarse_iters = [iter_num for iter_num, time in zip(data['iterations'], coarse_times) if time > 0]
                coarse_times_filtered = [time for time in coarse_times if time > 0]
                if coarse_iters:
                    ax.plot(coarse_iters, coarse_times_filtered, 'o-', 
                           label='Coarse', color='blue', alpha=0.7)
            
            if fine_op in data['operations']:
                fine_times = data['operations'][fine_op]
                fine_iters = [iter_num for iter_num, time in zip(data['iterations'], fine_times) if time > 0]
                fine_times_filtered = [time for time in fine_times if time > 0]
                if fine_iters:
                    ax.plot(fine_iters, fine_times_filtered, 's-', 
                           label='Fine', color='red', alpha=0.7)
            
            ax.set_xlabel('Iteration')
            ax.set_ylabel('Time (seconds)')
            ax.set_title(f'{op.replace("_", " ").title()} Time Trend')
            ax.legend()
            ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š æ“ä½œè¶‹åŠ¿å›¾å·²ä¿å­˜: {save_path}")
        
        plt.show()
    
    def plot_heatmap(self, save_path=None):
        """ç»˜åˆ¶æ“ä½œç”¨æ—¶çƒ­åŠ›å›¾"""
        data = self.extract_operation_data()
        
        # å‡†å¤‡çƒ­åŠ›å›¾æ•°æ®
        operations = []
        iterations = data['iterations']
        
        # æ”¶é›†æ‰€æœ‰æ“ä½œ
        for op in data['operations'].keys():
            if not op.endswith('_total'):
                operations.append(op)
        
        # åˆ›å»ºæ•°æ®çŸ©é˜µ
        matrix = []
        for op in operations:
            times = data['operations'][op]
            matrix.append(times)
        
        if not matrix:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æ“ä½œæ•°æ®")
            return
        
        # åˆ›å»ºçƒ­åŠ›å›¾
        fig, ax = plt.subplots(figsize=(12, 8))
        
        # ç»˜åˆ¶çƒ­åŠ›å›¾
        if HAS_SEABORN:
            sns.heatmap(matrix, 
                       xticklabels=iterations,
                       yticklabels=[op.replace('_', ' ').title() for op in operations],
                       cmap='YlOrRd',
                       cbar_kws={'label': 'ç”¨æ—¶ (ç§’)'},
                       ax=ax)
        else:
            # ä½¿ç”¨matplotlibç»˜åˆ¶çƒ­åŠ›å›¾
            im = ax.imshow(matrix, cmap='YlOrRd', aspect='auto')
            ax.set_xticks(range(len(iterations)))
            ax.set_xticklabels(iterations)
            ax.set_yticks(range(len(operations)))
            ax.set_yticklabels([op.replace('_', ' ').title() for op in operations])
            
            # æ·»åŠ é¢œè‰²æ¡
            cbar = plt.colorbar(im, ax=ax)
            cbar.set_label('ç”¨æ—¶ (ç§’)')
            
            # æ·»åŠ æ•°å€¼æ ‡æ³¨
            for i in range(len(operations)):
                for j in range(len(iterations)):
                    if matrix[i][j] > 0:
                        ax.text(j, i, f'{matrix[i][j]:.2f}', 
                               ha='center', va='center', fontsize=8)
        
        ax.set_title('Operation Time Heatmap')
        ax.set_xlabel('Iteration')
        ax.set_ylabel('Operation Type')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š çƒ­åŠ›å›¾å·²ä¿å­˜: {save_path}")
        
        plt.show()
    
    def generate_summary_report(self):
        """ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š"""
        data = self.extract_iteration_data()
        op_data = self.extract_operation_data()
        
        print("\n" + "="*60)
        print("ğŸ“Š 4DGSè®­ç»ƒæ—¶é—´åˆ†ææŠ¥å‘Š")
        print("="*60)
        
        # åŸºæœ¬ç»Ÿè®¡
        total_training_time = self.data.get('total_training_time', 0)
        print(f"æ€»è®­ç»ƒæ—¶é—´: {total_training_time:.2f} ç§’ ({total_training_time/60:.1f} åˆ†é’Ÿ)")
        
        if data['iterations']:
            avg_time = np.mean(data['total_times'])
            min_time = np.min(data['total_times'])
            max_time = np.max(data['total_times'])
            print(f"å¹³å‡æ¯è½®ç”¨æ—¶: {avg_time:.3f} ç§’")
            print(f"æœ€å¿«è½®æ¬¡: {min_time:.3f} ç§’")
            print(f"æœ€æ…¢è½®æ¬¡: {max_time:.3f} ç§’")
            print(f"æ€»è½®æ¬¡æ•°: {len(data['iterations'])}")
        
        # å„æ“ä½œå¹³å‡ç”¨æ—¶
        print("\nå„æ“ä½œå¹³å‡ç”¨æ—¶:")
        for op, times in op_data['operations'].items():
            if times and any(t > 0 for t in times):
                avg_time = np.mean([t for t in times if t > 0])
                print(f"  {op.replace('_', ' ').title()}: {avg_time:.3f} ç§’")
        
        # è®­ç»ƒæŒ‡æ ‡
        if data['losses'] and any(l > 0 for l in data['losses']):
            final_loss = data['losses'][-1] if data['losses'][-1] > 0 else data['losses'][-2]
            print(f"\næœ€ç»ˆæŸå¤±: {final_loss:.6f}")
        
        if data['psnrs'] and any(p > 0 for p in data['psnrs']):
            final_psnr = data['psnrs'][-1] if data['psnrs'][-1] > 0 else data['psnrs'][-2]
            print(f"æœ€ç»ˆPSNR: {final_psnr:.2f}")
        
        print("="*60)
    
    def run_full_analysis(self, output_dir=None):
        """è¿è¡Œå®Œæ•´åˆ†æ"""
        if output_dir:
            output_dir = Path(output_dir)
            output_dir.mkdir(exist_ok=True)
        
        print("ğŸš€ å¼€å§‹4DGSè®­ç»ƒæ—¶é—´å¯è§†åŒ–åˆ†æ...")
        
        # ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š
        self.generate_summary_report()
        
        # ç”Ÿæˆå„ç§å›¾è¡¨
        self.plot_iteration_timing_curve(
            save_path=output_dir / "iteration_timing_curve.png" if output_dir else None
        )
        
        self.plot_operation_breakdown(
            save_path=output_dir / "operation_breakdown.png" if output_dir else None
        )
        
        self.plot_operation_trends(
            save_path=output_dir / "operation_trends.png" if output_dir else None
        )
        
        self.plot_heatmap(
            save_path=output_dir / "operation_heatmap.png" if output_dir else None
        )
        
        print("âœ… åˆ†æå®Œæˆï¼")

def main():
    parser = argparse.ArgumentParser(description='4DGSè®­ç»ƒæ—¶é—´å¯è§†åŒ–åˆ†æå·¥å…·')
    parser.add_argument('timing_report', help='æ—¶é—´æŠ¥å‘ŠJSONæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', '-o', help='è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('--curve', action='store_true', help='åªæ˜¾ç¤ºç”¨æ—¶æ›²çº¿')
    parser.add_argument('--breakdown', action='store_true', help='åªæ˜¾ç¤ºæ“ä½œå æ¯”')
    parser.add_argument('--trends', action='store_true', help='åªæ˜¾ç¤ºæ“ä½œè¶‹åŠ¿')
    parser.add_argument('--heatmap', action='store_true', help='åªæ˜¾ç¤ºçƒ­åŠ›å›¾')
    
    args = parser.parse_args()
    
    # åˆ›å»ºå¯è§†åŒ–å™¨
    visualizer = TimingVisualizer(args.timing_report)
    
    # æ ¹æ®å‚æ•°é€‰æ‹©æ˜¾ç¤ºå†…å®¹
    if args.curve:
        visualizer.plot_iteration_timing_curve()
    elif args.breakdown:
        visualizer.plot_operation_breakdown()
    elif args.trends:
        visualizer.plot_operation_trends()
    elif args.heatmap:
        visualizer.plot_heatmap()
    else:
        # æ˜¾ç¤ºæ‰€æœ‰å›¾è¡¨
        visualizer.run_full_analysis(args.output)

if __name__ == "__main__":
    main()
